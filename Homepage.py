import streamlit as st
from langchain.schema import AIMessage, HumanMessage
from api import HuaweiPanguAPI
import ollama

st.set_page_config(page_title="Welcome to DonkChat", layout="wide")

# è®¾ç½® page_title ï¼Œæ ‡ç­¾æ çš„ title
st.title("ğŸƒâ€â™‚ï¸ Welcome to DonkChat")

# åˆå§‹åŒ– HuaweiPanguAPI å¯¹è±¡
chat = None

if "PANGU_API_KEY" not in st.session_state:
    st.session_state["PANGU_API_KEY"] = ""
if "PANGU_API_SECRET" not in st.session_state:
    st.session_state["PANGU_API_SECRET"] = ""

if "MODEL_CHOOSE" not in st.session_state:
    st.session_state["MODEL_CHOOSE"] = ""


# æ£€æŸ¥Panguå’Œæœ¬åœ°æ¨¡å‹æ˜¯å¦å­˜åœ¨
def check_models():
    return bool(st.session_state["MODEL_CHOOSE"] or (
                st.session_state["PANGU_API_KEY"] and st.session_state["PANGU_API_SECRET"]))


# éªŒè¯Panguå‡­è¯
def validate_pangu_credentials(api_key, api_secret):
    try:
        test_chat = HuaweiPanguAPI(api_key=api_key, api_secret=api_secret)
        test_chat([HumanMessage(content="ping")])  # éªŒè¯å‡­è¯æœ‰æ•ˆæ€§
        return True
    except:
        return False


# é¦–é¡µæ˜¾ç¤ºæ£€æŸ¥ç»“æœ
if not check_models():
    st.warning("Neither local model nor Pangu API is set up. Please configure at least one to proceed.")
    st.stop()
else:
    if st.session_state["PANGU_API_KEY"] and st.session_state["PANGU_API_SECRET"]:
        if validate_pangu_credentials(st.session_state["PANGU_API_KEY"], st.session_state["PANGU_API_SECRET"]):
            chat = HuaweiPanguAPI(api_key=st.session_state["PANGU_API_KEY"],
                                  api_secret=st.session_state["PANGU_API_SECRET"])
            st.success("Huawei Pangu API initialized successfully.")
        else:
            st.error("Invalid Pangu API Key or Secret. Please provide correct credentials.")
            st.stop()

# æ¶ˆæ¯æ¸²æŸ“å’Œå¯¹è¯æ¡†é€»è¾‘
with st.container():
    if chat:
        model_name = "Pangu"
    else:
        model_name = st.session_state['MODEL_CHOOSE']
    st.header(f"Chat with {model_name}!!")

    # æ¶ˆæ¯æ¸²æŸ“
    if "message" not in st.session_state:
        st.session_state["message"] = []

    for message in st.session_state.get("message", []):
        if isinstance(message, HumanMessage):
            with st.chat_message("user"):
                st.markdown(message.content)
        elif isinstance(message, AIMessage):
            with st.chat_message("assistant"):
                st.markdown(message.content)

    prompt = st.chat_input("Type something...")

    if prompt:
        # æ£€æŸ¥ç”¨æˆ·è¾“å…¥æ—¶ï¼Œåˆ¤æ–­æ¨¡å‹æ˜¯å¦å­˜åœ¨
        if not check_models():
            st.warning("Neither local model nor Pangu API is set up. Please configure at least one to proceed.")
        else:
            st.session_state["message"].append(HumanMessage(content=prompt))
            with st.chat_message("user"):
                st.markdown(prompt)

            if chat:
                ai_message = chat([HumanMessage(content=prompt)])
                st.session_state["message"].append(ai_message)
                with st.chat_message("assistant"):
                    st.markdown(ai_message.content)
            else:
                ai_message_content = ""
                message_placeholder = st.empty()
                for chunk in ollama.chat(
                        model=st.session_state["MODEL_CHOOSE"],
                        messages=[
                            {"role": m["role"], "content": m["content"]}
                            for m in st.session_state["message"]
                        ],
                        stream=True,
                ):
                    if 'message' in chunk and 'content' in chunk['message']:
                        ai_message_content += (chunk['message']['content'] or "")
                        message_placeholder.markdown(ai_message_content + "â–Œ")

                st.session_state['message'].append(AIMessage(content=ai_message_content))
                message_placeholder.markdown(ai_message_content)